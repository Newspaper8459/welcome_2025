{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7eea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uuekun/projects/huit/welcome_2025/backend/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from continuum.datasets import CIFAR10, ImageFolderDataset\n",
    "from continuum.scenarios import ClassIncremental\n",
    "from continuum.metrics import Logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac012653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "  dataset = 'cifar-10'\n",
    "  increment = 2\n",
    "  initial_increment = 2\n",
    "  log_path = Path('log') / f'{dataset}_{initial_increment}_{increment}'\n",
    "  batch_size_train = 32\n",
    "  batch_size_valid = 32\n",
    "\n",
    "  num_epochs = 300\n",
    "\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c2f0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    \"\"\"Fix all random seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc54dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalResNet50(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.backbone = models.resnet50()\n",
    "    self.transforms = models.ResNet50_Weights.IMAGENET1K_V1.transforms\n",
    "\n",
    "    self.backbone.fc = nn.Linear(self.backbone.fc.in_features, 0)\n",
    "    self.num_classes = 0\n",
    "\n",
    "  def adaptation(self, increment: int) -> None:\n",
    "    old_fc = self.backbone.fc\n",
    "    in_features = old_fc.in_features\n",
    "\n",
    "    new_fc = nn.Linear(in_features, self.num_classes + increment)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      new_fc.weight[:-increment] = old_fc.weight.detach().clone()\n",
    "\n",
    "    self.backbone.fc = new_fc\n",
    "    self.num_classes += increment\n",
    "\n",
    "  def forward(self, x) -> None:\n",
    "    x = self.backbone(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/.venv/lib/python3.12/site-packages/torch/nn/init.py:453: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model = IncrementalResNet50().to(cfg.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CIFAR10(data_path='input', train=True, download=True)\n",
    "dataset_valid = CIFAR10(data_path='input', train=False, download=True)\n",
    "\n",
    "scenario_train = ClassIncremental(dataset_train, increment=2, initial_increment=2, transformations=model.transforms)\n",
    "scenario_valid = ClassIncremental(dataset_valid, increment=2, initial_increment=2, transformations=model.transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.log_path.mkdir(parents=True, exist_ok=True)\n",
    "with open(cfg.log_path / 'metrics.json', 'w') as f:\n",
    "  pass\n",
    "\n",
    "metric_logger = Logger(list_subsets=['valid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8610a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_id in range(len(scenario_valid)):\n",
    "  logging.info(f'Train for task {task_id} has started.')\n",
    "  model.adaptation(cfg.initial_increment if task_id == 0 else cfg.increment)\n",
    "\n",
    "  dataloader_train = DataLoader(scenario_train[task_id], batch_size=cfg.batch_size_train, shuffle=True)\n",
    "  dataloader_valid = DataLoader(scenario_valid[:task_id], batch_size=cfg.batch_size_valid)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  optimizer = optim.AdamW(params=model.parameters())\n",
    "  scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=cfg.num_epochs)\n",
    "\n",
    "  for i_epoch in range(cfg.num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = torch.tensor(0.0).to(cfg.device)\n",
    "    tqdm_loader = tqdm(dataloader_train)\n",
    "\n",
    "    for X, y, task_ids in tqdm_loader:\n",
    "      X, y = X.to(cfg.device), y.to(cfg.device)\n",
    "\n",
    "      y_pred = model(X)\n",
    "\n",
    "      loss = F.cross_entropy(y_pred, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "\n",
    "      tqdm_loader.set_description(f'Epoch: {i_epoch}/{cfg.num_epochs} | Loss: {loss.item()}')\n",
    "\n",
    "  tqdm_loader = tqdm(dataloader_valid)\n",
    "  model.eval()\n",
    "  for X, y, task_ids in tqdm_loader:\n",
    "    X = X.to(cfg.device)\n",
    "\n",
    "    y_pred = model(X)\n",
    "    y_pred = F.softmax(y_pred)\n",
    "    metric_logger.add(y_pred.cpu().argmax(dim=1), y, task_ids, subset='valid')\n",
    "\n",
    "  with open(cfg.log_path / 'metrics.json', 'w+') as f:\n",
    "    d = json.load(f)\n",
    "    d[f'task_{task_id}'] = {\n",
    "      'task': task_id,\n",
    "      'acc': round(100 * metric_logger.accuracy, 2),\n",
    "      'avg_acc': round(100 * metric_logger.average_incremental_accuracy, 2),\n",
    "      'forgetting': round(100 * metric_logger.forgetting, 6),\n",
    "      'acc_per_task': [round(100 * acc_t, 2) for acc_t in metric_logger.accuracy_per_task],\n",
    "      'bwt': round(100 * metric_logger.backward_transfer, 2),\n",
    "      'fwt': round(100 * metric_logger.forward_transfer, 2),\n",
    "    }\n",
    "\n",
    "    json.dump(d, f, indent=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
